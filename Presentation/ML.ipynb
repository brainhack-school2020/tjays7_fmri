{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for creating training/ test sets and metrics evaluation for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_test():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def train_test_sets (self, df_features, df_labels):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "                                                        df_features, # x\n",
    "                                                        df_labels.values, # y\n",
    "                                                        test_size = 0.30, # 70%/30% split  \n",
    "                                                        shuffle = True, # shuffle dataset\n",
    "                                                                        # before splitting\n",
    "                                                        stratify = df_labels.values,  # keep\n",
    "                                                                               # distribution\n",
    "                                                                               # of Gender\n",
    "                                                                               # consistent\n",
    "                                                                               # betw. train\n",
    "                                                                               # & test sets.\n",
    "                                                        random_state = 123 # same shuffle each\n",
    "                                                                           # time\n",
    "                                                                           )\n",
    "\n",
    "        # print the size of our training and test groups\n",
    "\n",
    "        print('training:', len(X_train), 'testing:', len(X_val))\n",
    "        return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML_metrics():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    # Function Definition for Confusion Matrix\n",
    "\n",
    "    def conf_matrix(self, test_Y, prediction):\n",
    "        con_matrix = confusion_matrix(test_Y,prediction)\n",
    "        print('Confusion_matrix', con_matrix)\n",
    "        #plt.figure()\n",
    "        plt.matshow(con_matrix,cmap='Pastel1')\n",
    "        for x in range(0, 2):\n",
    "            for y in range(0,2):\n",
    "                plt.text(x,y,con_matrix[x, y])\n",
    "        plt.ylabel('Actual Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "       # plt.show()\n",
    "        print('True Negative = ',con_matrix[0][0])\n",
    "        print('False Negative = ',con_matrix[0][1])\n",
    "        print('False Positive = ',con_matrix[1][0])\n",
    "        print('True Positive = ',con_matrix[1][1])\n",
    "\n",
    "    def metrics (self, X_train, y_train, clf_names, classifiers):\n",
    "\n",
    "        for name, clf in zip(clf_names, classifiers):\n",
    "\n",
    "            print(\"{}\\n\\n\".format(name))\n",
    "\n",
    "            # predict\n",
    "            y_pred = cross_val_predict(clf, X_train, y_train, cv=10)\n",
    "\n",
    "            # scores\n",
    "            acc = cross_val_score(clf, X_train, y_train, cv=10).mean()\n",
    "            roc_auc = cross_val_score(clf, X_train, y_train, cv=10, scoring = 'roc_auc').mean()\n",
    "            f1 = cross_val_score(clf, X_train, y_train, cv=10, scoring = 'f1').mean()\n",
    "\n",
    "            print(\"Accuracy of {}: {}\".format(name,acc))\n",
    "            print(\"Area Under Curve of {}: {}\".format(name,roc_auc))\n",
    "            print(\"f1 score of {}: {}\".format(name, f1))\n",
    "\n",
    "            self.conf_matrix(y_train,y_pred)\n",
    "\n",
    "            print(\"==================================================================================================================\\n\\n\")\n",
    "\n",
    "        return  y_pred, acc, roc_auc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
